{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6UcfW6unb/lQS9A46/TWr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niklas-KOI/IANNWTF/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7VOZrQ3cNJi"
      },
      "source": [
        "import numpy as np\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from IPython import display\n",
        "import time \n",
        "# print(tf.__version__)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZWBAXNJaP7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33bbc6c-e77c-4f75-bad5-369b4c3e8641"
      },
      "source": [
        "import random\n",
        "BATCH=32\n",
        "matrix=np.load(\"Xfile.npy\",allow_pickle=True)\n",
        "target=np.load(\"yfile.npy\")\n",
        "print(target.shape)\n",
        "new_target=[]\n",
        "counter=0\n",
        "for i in range(len(matrix)):\n",
        "  new_target.append(target[counter:counter+len(matrix[i])])\n",
        "  counter+=len(matrix[i])\n",
        "\n",
        "\n",
        "def getDataset(matrix,new_target):\n",
        "  print(matrix[0].shape)\n",
        "  print(len(new_target))\n",
        "\n",
        "  X=[]\n",
        "  y=[]\n",
        "  for i in range(len(matrix)):\n",
        "    for j in range(1,len(matrix[i])-20):\n",
        "      X.append(matrix[i][j:j+20])\n",
        "      y.append(new_target[i][j-1:j+20])\n",
        "  print(np.array(X).shape)\n",
        "\n",
        "  data_set = tf.data.Dataset.from_tensor_slices(X)\n",
        "  y_set=tf.data.Dataset.from_tensor_slices(y)\n",
        "  y_set=y_set.map(lambda x:tf.cast(x,tf.float32))\n",
        "\n",
        "  final_set=tf.data.Dataset.zip((data_set,y_set))\n",
        "  #one hot encode the digits\n",
        "  final_set = final_set.shuffle(buffer_size=128)\n",
        "  final_set = final_set.batch(BATCH)\n",
        "  final_set = final_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return final_set\n",
        "train_dataset = getDataset(matrix[8:],new_target[8:])\n",
        "for i in train_dataset:\n",
        "  print(i)\n",
        "  break\n",
        "test_dataset = getDataset(matrix[:8],new_target[:8])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2177,)\n",
            "(5, 83)\n",
            "44\n",
            "(1052, 20, 83)\n",
            "(<tf.Tensor: shape=(32, 20, 83), dtype=float64, numpy=\n",
            "array([[[1.48983018e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         3.27054436e-05, 2.54990340e+02, 4.92309529e-05],\n",
            "        [1.48983018e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         2.48544348e-05, 2.50084477e+02, 3.78848108e-05],\n",
            "        [1.48983018e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         3.87739391e-05, 2.53763592e+02, 4.90606490e-05],\n",
            "        ...,\n",
            "        [1.48983018e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         7.41336398e-05, 2.53761849e+02, 4.85483182e-05],\n",
            "        [1.48983018e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         4.14668694e-05, 2.54565693e+02, 3.77377782e-05],\n",
            "        [1.48983018e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         5.57220149e-05, 2.53650276e+02, 5.35768954e-05]],\n",
            "\n",
            "       [[1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         2.85613113e-04, 2.67570510e+02, 1.97561742e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         2.24137875e-04, 2.67466165e+02, 1.48490449e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         2.03797703e-04, 2.66933154e+02, 2.51454764e-04],\n",
            "        ...,\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         2.31495502e-04, 2.68076827e+02, 2.21461055e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         9.93581301e-05, 2.68576560e+02, 1.47361738e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         9.91087059e-05, 2.67501001e+02, 2.57701369e-04]],\n",
            "\n",
            "       [[1.43471863e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         1.72567517e-05, 2.61143569e+02, 1.43937065e-05],\n",
            "        [1.43471863e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         4.65369582e-05, 2.65119986e+02, 7.04000818e-05],\n",
            "        [1.43471863e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         5.51163717e-05, 2.57303000e+02, 2.55047821e-05],\n",
            "        ...,\n",
            "        [1.40163882e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         1.32783817e-05, 2.67352552e+02, 5.50773139e-05],\n",
            "        [1.41581588e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         6.12948550e-05, 2.60680768e+02, 4.35112257e-05],\n",
            "        [1.43471863e-01, 1.42857143e-01, 1.42857143e-01, ...,\n",
            "         2.39528879e-05, 2.64956960e+02, 6.34612625e-05]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[1.25691773e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         1.68895339e-04, 2.73000750e+02, 2.21227897e-04],\n",
            "        [1.26184296e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         2.55429586e-04, 2.72115307e+02, 1.14941291e-04],\n",
            "        [1.43619597e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         1.77187719e-04, 2.65415210e+02, 1.05082577e-04],\n",
            "        ...,\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         2.53657361e-04, 2.66727588e+02, 1.52253810e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         1.86514394e-04, 2.66429340e+02, 1.97992824e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         2.63347652e-04, 2.69402566e+02, 1.52375930e-04]],\n",
            "\n",
            "       [[1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         1.82496588e-04, 2.66667924e+02, 1.52668926e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         2.11369485e-04, 2.66526989e+02, 2.00133574e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         1.01275113e-04, 2.67010308e+02, 1.26347749e-04],\n",
            "        ...,\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         1.36538593e-04, 2.66398276e+02, 2.29466757e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         1.52887482e-04, 2.65891825e+02, 1.41557045e-04],\n",
            "        [1.42142029e-01, 1.40028008e-01, 1.40028008e-01, ...,\n",
            "         1.25043860e-04, 2.67615621e+02, 2.09588390e-04]],\n",
            "\n",
            "       [[1.35171421e-01, 1.33630621e-01, 1.33630621e-01, ...,\n",
            "         1.70224836e-04, 2.69363615e+02, 1.66965228e-04],\n",
            "        [1.35171421e-01, 1.33630621e-01, 1.33630621e-01, ...,\n",
            "         1.91532984e-04, 2.69377961e+02, 1.16521225e-04],\n",
            "        [1.35171421e-01, 1.33630621e-01, 1.33630621e-01, ...,\n",
            "         1.53993748e-04, 2.71711784e+02, 1.30738751e-04],\n",
            "        ...,\n",
            "        [1.26266848e-01, 1.33630621e-01, 1.33630621e-01, ...,\n",
            "         1.40966034e-04, 2.72146732e+02, 1.29399027e-04],\n",
            "        [1.24485933e-01, 1.33630621e-01, 1.33630621e-01, ...,\n",
            "         1.86996869e-04, 2.73549353e+02, 2.53454181e-04],\n",
            "        [1.23595476e-01, 1.33630621e-01, 1.33630621e-01, ...,\n",
            "         1.37410406e-04, 2.73511808e+02, 1.85379337e-04]]])>, <tf.Tensor: shape=(32, 21), dtype=float32, numpy=\n",
            "array([[-1.64966693e-03, -1.64966693e-03, -1.64966693e-03,\n",
            "        -1.64966693e-03, -4.24845750e-03, -7.20881857e-03,\n",
            "        -1.67226512e-03,  8.58730753e-04, -2.48579960e-03,\n",
            "         4.70042089e-03,  3.61570856e-04, -1.42142540e-02,\n",
            "        -7.72857666e-03, -5.92072261e-03,  4.49703727e-03,\n",
            "        -7.23141665e-03, -1.69938300e-02, -2.48579960e-03,\n",
            "        -1.06211435e-02, -4.74561751e-03,  2.25981770e-04],\n",
            "       [ 1.52085740e-02,  1.80559438e-02, -1.20448284e-02,\n",
            "         2.19428297e-02,  7.90936220e-03, -1.32651301e-02,\n",
            "        -9.12966393e-03, -1.22256139e-02, -7.00543518e-04,\n",
            "        -1.65192671e-02, -2.96036131e-03, -5.71733899e-03,\n",
            "        -1.20900255e-02, -5.33316983e-03, -2.99877822e-02,\n",
            "        -8.83588754e-03, -6.66646240e-03, -6.25969516e-03,\n",
            "        -5.26537560e-03,  3.27673578e-03,  4.85860836e-03],\n",
            "       [ 2.57619214e-03, -2.74115894e-02, -2.96036131e-03,\n",
            "        -4.74561751e-03, -3.41232494e-02, -7.75117474e-03,\n",
            "        -7.77377328e-03, -6.75685517e-03,  1.27001759e-02,\n",
            "        -5.37836645e-03,  1.98186021e-02, -2.77279634e-02,\n",
            "        -9.78501048e-03, -4.99871671e-02, -2.08581183e-02,\n",
            "        -2.46998090e-02, -1.70390252e-02, -9.96579602e-03,\n",
            "        -7.61558581e-03, -4.25297692e-02, -2.96488088e-02],\n",
            "       [-7.00543518e-04, -1.65192671e-02, -2.96036131e-03,\n",
            "        -5.71733899e-03, -1.20900255e-02, -5.33316983e-03,\n",
            "        -2.99877822e-02, -8.83588754e-03, -6.66646240e-03,\n",
            "        -6.25969516e-03, -5.26537560e-03,  3.27673578e-03,\n",
            "         4.85860836e-03, -4.08575051e-02,  4.65522474e-03,\n",
            "        -1.23838009e-02,  9.03927139e-05, -1.89824693e-03,\n",
            "        -5.44390082e-02, -1.13442848e-02, -8.22573621e-03],\n",
            "       [-7.32180942e-03, -2.94680241e-02, -1.76039804e-02,\n",
            "        -9.03927139e-05, -1.18866414e-02, -2.14004740e-02,\n",
            "        -1.65644642e-02, -2.08807159e-02, -2.42026486e-02,\n",
            "        -4.49251756e-02, -3.03719509e-02, -2.54229493e-02,\n",
            "        -2.37732828e-02, -4.72301897e-03, -6.28229324e-03,\n",
            "        -1.16832582e-02, -2.41348539e-02, -4.63940576e-02,\n",
            "        -1.27453720e-02, -2.22592056e-02, -5.17498283e-03],\n",
            "       [ 1.28809614e-02, -7.32180942e-03, -2.94680241e-02,\n",
            "        -1.76039804e-02, -9.03927139e-05, -1.18866414e-02,\n",
            "        -2.14004740e-02, -1.65644642e-02, -2.08807159e-02,\n",
            "        -2.42026486e-02, -4.49251756e-02, -3.03719509e-02,\n",
            "        -2.54229493e-02, -2.37732828e-02, -4.72301897e-03,\n",
            "        -6.28229324e-03, -1.16832582e-02, -2.41348539e-02,\n",
            "        -4.63940576e-02, -1.27453720e-02, -2.22592056e-02],\n",
            "       [-2.46998090e-02, -1.70390252e-02, -9.96579602e-03,\n",
            "        -7.61558581e-03, -4.25297692e-02, -2.96488088e-02,\n",
            "        -1.90954600e-02, -2.18976345e-02, -2.35021040e-02,\n",
            "        -2.11970899e-02, -2.23721955e-02, -1.78525597e-02,\n",
            "        -5.15238456e-02, -4.54223379e-02, -5.61790690e-02,\n",
            "        -4.99419728e-03, -2.00671814e-02, -5.53655364e-02,\n",
            "         1.40108699e-02,  2.93776300e-03, -1.71746146e-02],\n",
            "       [-1.53667610e-02,  2.57619214e-03, -2.74115894e-02,\n",
            "        -2.96036131e-03, -4.74561751e-03, -3.41232494e-02,\n",
            "        -7.75117474e-03, -7.77377328e-03, -6.75685517e-03,\n",
            "         1.27001759e-02, -5.37836645e-03,  1.98186021e-02,\n",
            "        -2.77279634e-02, -9.78501048e-03, -4.99871671e-02,\n",
            "        -2.08581183e-02, -2.46998090e-02, -1.70390252e-02,\n",
            "        -9.96579602e-03, -7.61558581e-03, -4.25297692e-02],\n",
            "       [ 1.15250703e-03, -2.24625878e-02,  1.52085740e-02,\n",
            "         1.80559438e-02, -1.20448284e-02,  2.19428297e-02,\n",
            "         7.90936220e-03, -1.32651301e-02, -9.12966393e-03,\n",
            "        -1.22256139e-02, -7.00543518e-04, -1.65192671e-02,\n",
            "        -2.96036131e-03, -5.71733899e-03, -1.20900255e-02,\n",
            "        -5.33316983e-03, -2.99877822e-02, -8.83588754e-03,\n",
            "        -6.66646240e-03, -6.25969516e-03, -5.26537560e-03],\n",
            "       [-2.54229493e-02, -2.37732828e-02, -4.72301897e-03,\n",
            "        -6.28229324e-03, -1.16832582e-02, -2.41348539e-02,\n",
            "        -4.63940576e-02, -1.27453720e-02, -2.22592056e-02,\n",
            "        -5.17498283e-03, -2.23721955e-02, -6.12636581e-02,\n",
            "        -2.58975122e-02, -3.41684446e-02, -4.50833626e-02,\n",
            "        -3.32871154e-02, -3.61796841e-02, -1.99541915e-02,\n",
            "        -2.95358188e-02, -4.07219157e-02, -4.61002812e-02],\n",
            "       [-1.64966693e-03, -4.24845750e-03, -7.20881857e-03,\n",
            "        -1.67226512e-03,  8.58730753e-04, -2.48579960e-03,\n",
            "         4.70042089e-03,  3.61570856e-04, -1.42142540e-02,\n",
            "        -7.72857666e-03, -5.92072261e-03,  4.49703727e-03,\n",
            "        -7.23141665e-03, -1.69938300e-02, -2.48579960e-03,\n",
            "        -1.06211435e-02, -4.74561751e-03,  2.25981770e-04,\n",
            "        -1.76265780e-02, -1.17510520e-02, -1.67226512e-02],\n",
            "       [-1.64966693e-03, -1.64966693e-03, -1.64966693e-03,\n",
            "        -1.64966693e-03, -1.64966693e-03, -4.24845750e-03,\n",
            "        -7.20881857e-03, -1.67226512e-03,  8.58730753e-04,\n",
            "        -2.48579960e-03,  4.70042089e-03,  3.61570856e-04,\n",
            "        -1.42142540e-02, -7.72857666e-03, -5.92072261e-03,\n",
            "         4.49703727e-03, -7.23141665e-03, -1.69938300e-02,\n",
            "        -2.48579960e-03, -1.06211435e-02, -4.74561751e-03],\n",
            "       [-4.04507369e-02, -5.05973212e-02, -6.32297024e-02,\n",
            "        -5.29249310e-02, -4.25975658e-02, -3.31063308e-02,\n",
            "         4.76821559e-03, -2.42478438e-02, -6.44048080e-02,\n",
            "         3.38972658e-02,  2.48579960e-03, -1.35589065e-02,\n",
            "        -5.74897639e-02, -4.28235456e-02, -4.50833626e-02,\n",
            "        -6.24839626e-02, -6.21449873e-02, -4.74561751e-03,\n",
            "        -5.19758090e-02, -1.15250703e-02, -4.29365365e-03],\n",
            "       [-7.72857666e-03, -5.92072261e-03,  4.49703727e-03,\n",
            "        -7.23141665e-03, -1.69938300e-02, -2.48579960e-03,\n",
            "        -1.06211435e-02, -4.74561751e-03,  2.25981770e-04,\n",
            "        -1.76265780e-02, -1.17510520e-02, -1.67226512e-02,\n",
            "        -5.87552600e-03,  3.61570856e-04,  4.51963540e-04,\n",
            "         6.55347155e-03, -4.29365365e-03, -8.13534390e-03,\n",
            "        -2.67110467e-02, -2.04513501e-02, -7.93196075e-03],\n",
            "       [-8.81328899e-03, -8.81328899e-03, -5.83032984e-03,\n",
            "        -1.64966693e-03, -1.64966693e-03, -1.64966693e-03,\n",
            "        -1.64966693e-03, -1.64966693e-03, -1.64966693e-03,\n",
            "        -4.24845750e-03, -7.20881857e-03, -1.67226512e-03,\n",
            "         8.58730753e-04, -2.48579960e-03,  4.70042089e-03,\n",
            "         3.61570856e-04, -1.42142540e-02, -7.72857666e-03,\n",
            "        -5.92072261e-03,  4.49703727e-03, -7.23141665e-03],\n",
            "       [-7.68338051e-03, -4.72301897e-03, -7.23141665e-03,\n",
            "        -3.90496515e-02, -3.01459692e-02, -1.78073645e-02,\n",
            "        -3.38972663e-03, -3.77389565e-02, -4.04507369e-02,\n",
            "        -5.05973212e-02, -6.32297024e-02, -5.29249310e-02,\n",
            "        -4.25975658e-02, -3.31063308e-02,  4.76821559e-03,\n",
            "        -2.42478438e-02, -6.44048080e-02,  3.38972658e-02,\n",
            "         2.48579960e-03, -1.35589065e-02, -5.74897639e-02],\n",
            "       [-4.25297692e-02, -2.96488088e-02, -1.90954600e-02,\n",
            "        -2.18976345e-02, -2.35021040e-02, -2.11970899e-02,\n",
            "        -2.23721955e-02, -1.78525597e-02, -5.15238456e-02,\n",
            "        -4.54223379e-02, -5.61790690e-02, -4.99419728e-03,\n",
            "        -2.00671814e-02, -5.53655364e-02,  1.40108699e-02,\n",
            "         2.93776300e-03, -1.71746146e-02, -2.77957576e-03,\n",
            "        -2.24851873e-02, -4.99419719e-02, -2.92646401e-02],\n",
            "       [-3.56147289e-02, -5.89812454e-03, -7.32180942e-03,\n",
            "        -7.90936220e-03,  1.15250703e-03, -2.24625878e-02,\n",
            "         1.52085740e-02,  1.80559438e-02, -1.20448284e-02,\n",
            "         2.19428297e-02,  7.90936220e-03, -1.32651301e-02,\n",
            "        -9.12966393e-03, -1.22256139e-02, -7.00543518e-04,\n",
            "        -1.65192671e-02, -2.96036131e-03, -5.71733899e-03,\n",
            "        -1.20900255e-02, -5.33316983e-03, -2.99877822e-02],\n",
            "       [ 2.38636751e-02, -1.99993867e-02,  1.28809614e-02,\n",
            "        -7.32180942e-03, -2.94680241e-02, -1.76039804e-02,\n",
            "        -9.03927139e-05, -1.18866414e-02, -2.14004740e-02,\n",
            "        -1.65644642e-02, -2.08807159e-02, -2.42026486e-02,\n",
            "        -4.49251756e-02, -3.03719509e-02, -2.54229493e-02,\n",
            "        -2.37732828e-02, -4.72301897e-03, -6.28229324e-03,\n",
            "        -1.16832582e-02, -2.41348539e-02, -4.63940576e-02],\n",
            "       [-2.77279634e-02, -9.78501048e-03, -4.99871671e-02,\n",
            "        -2.08581183e-02, -2.46998090e-02, -1.70390252e-02,\n",
            "        -9.96579602e-03, -7.61558581e-03, -4.25297692e-02,\n",
            "        -2.96488088e-02, -1.90954600e-02, -2.18976345e-02,\n",
            "        -2.35021040e-02, -2.11970899e-02, -2.23721955e-02,\n",
            "        -1.78525597e-02, -5.15238456e-02, -4.54223379e-02,\n",
            "        -5.61790690e-02, -4.99419728e-03, -2.00671814e-02],\n",
            "       [-8.90368223e-03,  9.31044947e-03,  6.86984602e-03,\n",
            "         3.86428833e-03, -3.56147289e-02, -5.89812454e-03,\n",
            "        -7.32180942e-03, -7.90936220e-03,  1.15250703e-03,\n",
            "        -2.24625878e-02,  1.52085740e-02,  1.80559438e-02,\n",
            "        -1.20448284e-02,  2.19428297e-02,  7.90936220e-03,\n",
            "        -1.32651301e-02, -9.12966393e-03, -1.22256139e-02,\n",
            "        -7.00543518e-04, -1.65192671e-02, -2.96036131e-03],\n",
            "       [-2.37732828e-02, -4.72301897e-03, -6.28229324e-03,\n",
            "        -1.16832582e-02, -2.41348539e-02, -4.63940576e-02,\n",
            "        -1.27453720e-02, -2.22592056e-02, -5.17498283e-03,\n",
            "        -2.23721955e-02, -6.12636581e-02, -2.58975122e-02,\n",
            "        -3.41684446e-02, -4.50833626e-02, -3.32871154e-02,\n",
            "        -3.61796841e-02, -1.99541915e-02, -2.95358188e-02,\n",
            "        -4.07219157e-02, -4.61002812e-02, -1.22482125e-02],\n",
            "       [-2.24625878e-02,  1.52085740e-02,  1.80559438e-02,\n",
            "        -1.20448284e-02,  2.19428297e-02,  7.90936220e-03,\n",
            "        -1.32651301e-02, -9.12966393e-03, -1.22256139e-02,\n",
            "        -7.00543518e-04, -1.65192671e-02, -2.96036131e-03,\n",
            "        -5.71733899e-03, -1.20900255e-02, -5.33316983e-03,\n",
            "        -2.99877822e-02, -8.83588754e-03, -6.66646240e-03,\n",
            "        -6.25969516e-03, -5.26537560e-03,  3.27673578e-03],\n",
            "       [ 8.54211114e-03, -2.30727401e-02,  2.63494756e-02,\n",
            "         2.38636751e-02, -1.99993867e-02,  1.28809614e-02,\n",
            "        -7.32180942e-03, -2.94680241e-02, -1.76039804e-02,\n",
            "        -9.03927139e-05, -1.18866414e-02, -2.14004740e-02,\n",
            "        -1.65644642e-02, -2.08807159e-02, -2.42026486e-02,\n",
            "        -4.49251756e-02, -3.03719509e-02, -2.54229493e-02,\n",
            "        -2.37732828e-02, -4.72301897e-03, -6.28229324e-03],\n",
            "       [-1.22256139e-02, -7.00543518e-04, -1.65192671e-02,\n",
            "        -2.96036131e-03, -5.71733899e-03, -1.20900255e-02,\n",
            "        -5.33316983e-03, -2.99877822e-02, -8.83588754e-03,\n",
            "        -6.66646240e-03, -6.25969516e-03, -5.26537560e-03,\n",
            "         3.27673578e-03,  4.85860836e-03, -4.08575051e-02,\n",
            "         4.65522474e-03, -1.23838009e-02,  9.03927139e-05,\n",
            "        -1.89824693e-03, -5.44390082e-02, -1.13442848e-02],\n",
            "       [-1.32651301e-02, -9.12966393e-03, -1.22256139e-02,\n",
            "        -7.00543518e-04, -1.65192671e-02, -2.96036131e-03,\n",
            "        -5.71733899e-03, -1.20900255e-02, -5.33316983e-03,\n",
            "        -2.99877822e-02, -8.83588754e-03, -6.66646240e-03,\n",
            "        -6.25969516e-03, -5.26537560e-03,  3.27673578e-03,\n",
            "         4.85860836e-03, -4.08575051e-02,  4.65522474e-03,\n",
            "        -1.23838009e-02,  9.03927139e-05, -1.89824693e-03],\n",
            "       [ 2.19428297e-02,  7.90936220e-03, -1.32651301e-02,\n",
            "        -9.12966393e-03, -1.22256139e-02, -7.00543518e-04,\n",
            "        -1.65192671e-02, -2.96036131e-03, -5.71733899e-03,\n",
            "        -1.20900255e-02, -5.33316983e-03, -2.99877822e-02,\n",
            "        -8.83588754e-03, -6.66646240e-03, -6.25969516e-03,\n",
            "        -5.26537560e-03,  3.27673578e-03,  4.85860836e-03,\n",
            "        -4.08575051e-02,  4.65522474e-03, -1.23838009e-02],\n",
            "       [-2.08581183e-02, -2.46998090e-02, -1.70390252e-02,\n",
            "        -9.96579602e-03, -7.61558581e-03, -4.25297692e-02,\n",
            "        -2.96488088e-02, -1.90954600e-02, -2.18976345e-02,\n",
            "        -2.35021040e-02, -2.11970899e-02, -2.23721955e-02,\n",
            "        -1.78525597e-02, -5.15238456e-02, -4.54223379e-02,\n",
            "        -5.61790690e-02, -4.99419728e-03, -2.00671814e-02,\n",
            "        -5.53655364e-02,  1.40108699e-02,  2.93776300e-03],\n",
            "       [-2.18976345e-02, -2.35021040e-02, -2.11970899e-02,\n",
            "        -2.23721955e-02, -1.78525597e-02, -5.15238456e-02,\n",
            "        -4.54223379e-02, -5.61790690e-02, -4.99419728e-03,\n",
            "        -2.00671814e-02, -5.53655364e-02,  1.40108699e-02,\n",
            "         2.93776300e-03, -1.71746146e-02, -2.77957576e-03,\n",
            "        -2.24851873e-02, -4.99419719e-02, -2.92646401e-02,\n",
            "        -4.29365374e-02, -3.38972663e-03, -1.10731069e-02],\n",
            "       [ 9.31044947e-03,  6.86984602e-03,  3.86428833e-03,\n",
            "        -3.56147289e-02, -5.89812454e-03, -7.32180942e-03,\n",
            "        -7.90936220e-03,  1.15250703e-03, -2.24625878e-02,\n",
            "         1.52085740e-02,  1.80559438e-02, -1.20448284e-02,\n",
            "         2.19428297e-02,  7.90936220e-03, -1.32651301e-02,\n",
            "        -9.12966393e-03, -1.22256139e-02, -7.00543518e-04,\n",
            "        -1.65192671e-02, -2.96036131e-03, -5.71733899e-03],\n",
            "       [-7.32180942e-03, -7.90936220e-03,  1.15250703e-03,\n",
            "        -2.24625878e-02,  1.52085740e-02,  1.80559438e-02,\n",
            "        -1.20448284e-02,  2.19428297e-02,  7.90936220e-03,\n",
            "        -1.32651301e-02, -9.12966393e-03, -1.22256139e-02,\n",
            "        -7.00543518e-04, -1.65192671e-02, -2.96036131e-03,\n",
            "        -5.71733899e-03, -1.20900255e-02, -5.33316983e-03,\n",
            "        -2.99877822e-02, -8.83588754e-03, -6.66646240e-03],\n",
            "       [-4.49251756e-02, -3.03719509e-02, -2.54229493e-02,\n",
            "        -2.37732828e-02, -4.72301897e-03, -6.28229324e-03,\n",
            "        -1.16832582e-02, -2.41348539e-02, -4.63940576e-02,\n",
            "        -1.27453720e-02, -2.22592056e-02, -5.17498283e-03,\n",
            "        -2.23721955e-02, -6.12636581e-02, -2.58975122e-02,\n",
            "        -3.41684446e-02, -4.50833626e-02, -3.32871154e-02,\n",
            "        -3.61796841e-02, -1.99541915e-02, -2.95358188e-02]], dtype=float32)>)\n",
            "(53, 83)\n",
            "8\n",
            "(192, 20, 83)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjOxm4engqD"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "# A normal LSTM, we have the lstm_cell, small readin and readout layers, an output of 1 (binary classification)\n",
        "class LSTM(Model):\n",
        "\n",
        "  def __init__(self,input_dim,embedd_out,lstmsize):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.reshape=tf.keras.layers.Reshape((30,))\n",
        "    self.readin=tf.keras.layers.Embedding(input_dim=input_dim,output_dim=embedd_out)\n",
        "    self.lstm=tf.keras.layers.LSTMCell(units=lstmsize)\n",
        "    self.readout=tf.keras.layers.Dense(units=1,activation=tf.keras.activations.tanh)\n",
        "    self.lstmsize=lstmsize\n",
        "\n",
        "  @tf.function\n",
        "  def call(self,input,targets,howLongBeNice):\n",
        "    print(input.shape,targets.shape)\n",
        "    #define our starting hidden/cell states\n",
        "    h=tf.ones((len(input),self.lstmsize))*targets[:,0]\n",
        "    c=tf.zeros((len(input),self.lstmsize))\n",
        "    for i in range(len(input[0])):\n",
        "      timed_input=input[:,i] #take the input for this timestep for all the different batches\n",
        "      timed_input=self.readin(timed_input)\n",
        "      h,c=self.lstm(timed_input,(h,c))\n",
        "      h= h if i>=howLongBeNice else targets[i+1]\n",
        "      x=self.readout(h) #what was the output for this time step\n",
        "    return x\n",
        "    \n",
        "      "
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPEzxpnRPT4e"
      },
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "  # as always\n",
        "  with tf.GradientTape() as tape:\n",
        "    print(input.shape)\n",
        "    prediction = model(input,target,10)\n",
        "    loss = loss_function(target, prediction)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss \n",
        "\n",
        "def test(model, test_data, loss_function):\n",
        "  # as always\n",
        "\n",
        "  test_accuracy_aggregator = []\n",
        "  test_loss_aggregator = []\n",
        "\n",
        "  for (input, target) in test_data:\n",
        "    prediction = model(input)\n",
        "\n",
        "    sample_test_loss = loss_function(target, prediction)\n",
        "    prediction=tf.math.round(prediction)\n",
        "    #target=tf.math.round(target)\n",
        "    sample_test_accuracy =  tf.math.equal(target,prediction)\n",
        "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
        "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
        "\n",
        "  test_loss = np.mean(test_loss_aggregator)\n",
        "  test_accuracy = np.mean(test_accuracy_aggregator)\n",
        "\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYgwmK6pPlk3"
      },
      "source": [
        "\n",
        "def plot_accuracy(train_losses,test_losses,test_accuracies):\n",
        "  # Plot training and test loss.\n",
        "  plt.figure()\n",
        "  line1, = plt.plot(train_losses)\n",
        "  line2, = plt.plot(test_losses)\n",
        "  plt.xlabel(\"Training steps\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend((line1,line2),(\"training\",\"test\"))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot test accuracy.\n",
        "  plt.figure()\n",
        "  line1, = plt.plot(test_accuracies)\n",
        "  plt.title(f'Total Acuraccy: {np.max(test_accuracies)}')\n",
        "  plt.xlabel(\"Training steps\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.show()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wMTSVDu0PnkZ",
        "outputId": "57860996-3d68-4430-b298-966f699d6d03"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "### Hyperparameters\n",
        "num_epochs = 30\n",
        "learning_rate = 0.0001\n",
        "running_average_factor = 0.95\n",
        "\n",
        "# Set the time\n",
        "start = time.time()\n",
        "\n",
        "model=LSTM(83,8,32)\n",
        "\n",
        "# Initialize the loss: mean squared error Check out 'tf.keras.losses'.\n",
        "cross_entropy_loss = tf.keras.losses.MeanSquaredError\n",
        "# Initialize the optimizer: Adam with default parameters. Check out 'tf.keras.optimizers'\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "train_losses = []\n",
        "\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "#testing once before we begin\n",
        "#test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
        "#test_losses.append(test_loss)\n",
        "#test_accuracies.append(test_accuracy)\n",
        "\n",
        "#check how model performs on train data once before we begin\n",
        "#train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
        "#train_losses.append(train_loss)\n",
        "\n",
        "# We train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch: __ ' + str(epoch))\n",
        "\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=128)\n",
        "    test_dataset = test_dataset.shuffle(buffer_size=128)\n",
        "\n",
        "    #training\n",
        "    running_average = 0\n",
        "    for (input,target) in train_dataset:\n",
        "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
        "        running_average = running_average_factor * running_average  + (1 - running_average_factor) * train_loss\n",
        "    train_losses.append(running_average)\n",
        "\n",
        "    #testing\n",
        "    test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    \n",
        "    plot_accuracy(train_losses, test_losses, test_accuracies)\n",
        "\n",
        "# Keep track of the time \n",
        "end = time.time()\n",
        "duration = end - start\n",
        "\n",
        "print(f'\\nThis training took: {int (duration / 60)} minutes and {(duration % 60)} seconds.')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: __ 0\n",
            "(32, 20, 83)\n",
            "(32, 20, 83) (32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-c452c8185318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mrunning_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mrunning_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_average_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrunning_average\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrunning_average_factor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-4c571f727883>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, input, target, loss_function, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3885\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-73-6d0755b3a884>:23 call  *\n        h,c=self.lstm(timed_input,(h,c))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py:2454 call\n        z += K.dot(h_tm1, self.recurrent_kernel)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1486 _add_dispatch\n        return gen_math_ops.add_v2(x, y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py:482 add_v2\n        \"AddV2\", x=x, y=y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 83 and 32 for '{{node lstm_cell/add}} = AddV2[T=DT_FLOAT](lstm_cell/Reshape_2, lstm_cell/MatMul_1)' with input shapes: [32,83,128], [32,128].\n"
          ]
        }
      ]
    }
  ]
}